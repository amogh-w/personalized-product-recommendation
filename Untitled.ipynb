{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1acd6759",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ebd541-fcba-432b-803d-4d9bbd43f572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saura\\miniconda3\\envs\\proj_rec\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub as kh\n",
    "import sqlite3 as s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325dc5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.8)\n",
      "Path to dataset files: C:\\Users\\saura\\.cache\\kagglehub\\datasets\\snap\\amazon-fine-food-reviews\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "path = kh.dataset_download(\"snap/amazon-fine-food-reviews\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "conn = s3.connect(path+'/database.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b11d79",
   "metadata": {},
   "source": [
    "## Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9172e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc3b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"\"\" SELECT * FROM Reviews\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e2c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568454 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568454 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ceedef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          user_id     item_id  rating\n",
      "0  A3SGXH7AUHU8GW  B001E4KFG0       5\n",
      "1  A1D87F6ZCVE5NK  B00813GRG4       1\n",
      "2   ABXLMWJIXXAIN  B000LQOCH0       4\n",
      "3  A395BORC6FGVXV  B000UA0QIQ       2\n",
      "4  A1UQRSCLF8GW1T  B006K2ZZ7K       5\n"
     ]
    }
   ],
   "source": [
    "df = df[['UserId', 'ProductId', 'Score']]\n",
    "df.columns = ['user_id', 'item_id', 'rating']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80e7c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size after cleaning: (562630, 3)\n",
      "Dataset size after filtering: (189648, 3)\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Dataset size after cleaning: {df.shape}\")\n",
    "\n",
    "df['user_id'] = df['user_id'].astype(str)\n",
    "df['item_id'] = df['item_id'].astype(str)\n",
    "df['rating'] = df['rating'].astype(float)\n",
    "\n",
    "# Keep users with at least 5 reviews\n",
    "min_reviews = 5\n",
    "user_counts = df['user_id'].value_counts()\n",
    "df = df[df['user_id'].isin(user_counts[user_counts >= min_reviews].index)]\n",
    "\n",
    "# Keep products with at least 5 reviews\n",
    "item_counts = df['item_id'].value_counts()\n",
    "df = df[df['item_id'].isin(item_counts[item_counts >= min_reviews].index)]\n",
    "\n",
    "print(f\"Dataset size after filtering: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "558ee407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reader with the rating scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the dataset into Surprise format\n",
    "data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63883a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x257117f5640>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVD\n",
    "svd_model = SVD()\n",
    "svd_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b381b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7911\n",
      "Test RMSE: 0.7910868477497006\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = svd_model.test(testset)\n",
    "\n",
    "# Calculate RMSE (Root Mean Square Error)\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"Test RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d74fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x257117e5790>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Train-test split\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Train SVD model\n",
    "model = SVD()\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e0f5a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7974\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Evaluate RMSE\n",
    "rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92b5eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('B000ED9L9E', 4.850989917835667), ('B001ONPMN2', 4.781103115979346), ('B000EDG3UE', 4.773104683554928), ('B000H7ELTW', 4.772782748736063), ('B0054TWQMM', 4.7576378360660145)]\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_recommendations(model, user_id, n=5):\n",
    "    all_products = df['item_id'].unique()\n",
    "    predictions = [(item, model.predict(user_id, item).est) for item in all_products]\n",
    "    top_n = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "    return top_n\n",
    "\n",
    "# Example: Get top 5 recommendations for user 123\n",
    "recommendations = get_top_n_recommendations(model, user_id=123, n=5)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c81c7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [50, 100, 150],\n",
    "    'n_epochs': [10, 20],\n",
    "    'lr_all': [0.002, 0.005],\n",
    "    'reg_all': [0.02, 0.1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "grid_search.fit(data)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator['rmse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c116cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "with open(\"recommendation_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fabfd146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "with open(\"recommendation_model.pkl\", \"rb\") as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf819e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_rec_kernel",
   "language": "python",
   "name": "proj_rec_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
